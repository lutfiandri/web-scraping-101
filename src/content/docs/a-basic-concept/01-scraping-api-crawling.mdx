---
title: A.1. Scraping, API, dan Crawling
description: Konsep dasar serta perbedaan scraping, crawling, dan API
---

import { Aside } from "@astrojs/starlight/components";

Selamat datang di dunia perburuan data! Sebelum kita terjun dan mengotori tangan dengan kode, kita harus kenalan dulu sama tiga "senjata" utama kita: Scraping, API, dan Crawling.

Bayangin kamu adalah seorang detektif yang ditugaskan untuk mengumpulkan semua informasi tentang penjahat dari sebuah buku catatan tebal. Gimana caramu melakukannya? Ada tiga cara.

## Web Scraping: Si Pekerja Paksa

Cara pertama, kamu fotokopi semua halaman buku itu, lalu kamu gunting dan tempel informasi yang penting (nama, alamat, kejahatan) ke dalam laporanmu. Melelahkan, kan?

**Web Scraping itu persis kayak gitu, tapi pakai robot.** Kamu suruh sebuah program (scraper) untuk "melihat" halaman web sama seperti manusia, lalu secara paksa "menggunting" data yang kamu mau dari tampilan visualnya (kode HTML).

<Aside>
  Scraping itu seperti menyewa asisten super cepat yang bisa membaca ribuan
  halaman web dalam sekejap dan mencatat semua informasi yang kamu suruh. Dia
  gak peduli tulisannya jelek atau halamannya lecek, yang penting datanya dapet.
</Aside>

Intinya, scraping bekerja dengan meniru cara manusia berinteraksi dengan website, tapi dalam skala super masif.

## API: Si Jalur Resmi

Cara kedua, ternyata penulis buku catatan itu sudah baik hati. Dia menyediakan sebuah formulir permintaan. Kamu tinggal isi "Tolong berikan data semua penjahat," dan dia akan memberimu salinan data yang sudah rapi dalam format Excel. Enak, kan?

Itulah **API (Application Programming Interface)**.

API adalah "pintu resmi" yang sengaja dibuat oleh pemilik website agar program lain bisa meminta data secara terstruktur dan sopan. Kalau ada API, hidup kita sebagai pemburu data jadi jauh lebih mudah.

| Fitur           | Web Scraping (Lewat Jendela)                                               | API (Lewat Pintu Depan)                                                                 |
| :-------------- | :------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------- |
| **Sumber Data** | Kode HTML yang acak-acakan.                                                | Data JSON/XML yang bersih dan rapi.                                                     |
| **Cara Kerja**  | "Merampok" data dari tampilan.                                             | "Meminta izin" lewat jalur resmi.                                                       |
| **Kestabilan**  | **Sangat rapuh.** Tampilan web berubah dikit, scraper kamu langsung error. | **Sangat stabil.** Jarang berubah, kalaupun ada, biasanya ada versi baru (mis. API v2). |
| **Etika**       | Abu-abu. Bisa dianggap mengganggu.                                         | Jelas etis dan diizinkan.                                                               |
| **Pilihan**     | Pilihan terakhir kalau API tidak ada.                                      | **Selalu jadi pilihan pertama!**                                                        |

## Web Crawling: Si Pembuat Peta

Cara ketiga, sebelum kamu mengambil datanya, kamu harus tahu dulu di halaman berapa saja informasi para penjahat itu ada. Mungkin ada di halaman 5, 17, 23, dan seterusnya.

**Web Crawling adalah proses membuat "daftar isi" atau "peta" dari sebuah website.**

Crawler adalah program yang tugasnya cuma satu: menjelajahi website dari satu link ke link lainnya untuk menemukan semua halaman yang ada. Dia gak peduli isi halamannya apa, yang penting semua alamat halaman tercatat.

<Aside>
  Google adalah crawler terbesar di dunia. Googlebot-nya menjelajahi triliunan
  halaman web hanya untuk tahu "internet itu isinya apa aja sih?" biar kamu bisa
  mencarinya.
</Aside>

### Hubungan Cinta Crawling & Scraping

Keduanya ini seperti Batman dan Robin, sering bekerja sama.

1.  **Crawling membuat peta:** Kamu lepas crawler di halaman utama `situsberita.com`. Dia akan menjelajahi dan memberimu daftar URL semua artikel berita yang ada.
2.  **Scraping menjarah isinya:** Setelah kamu dapat daftar URL dari crawler, kamu kirim scraper ke tiap URL itu untuk mengambil judul, isi berita, dan nama penulisnya.

## Ringkasan Cepat

Kalau diibaratkan lagi, misinya adalah menjarah kastil:

- **Crawler**: "Aku akan gambar denah seluruh kastil dan menandai semua pintu harta karun!"
- **Scraper**: "Bagus! Sekarang aku akan dobrak setiap pintu itu dan ambil semua emasnya!"
- **API**: "Permisi Tuan Raja, bolehkah saya meminta sedikit emas? Ini surat izinnya."

Paham bedanya, kan? Dengan bekal ini, kamu siap untuk petualangan selanjutnya.
